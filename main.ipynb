{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "role = 'arn:aws:iam::484906661071:role/sagemaker'\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"sagemaker/sentence-transformers/multi-qa-mpnet-base-dot-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "model.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 419M\n",
      "-rw-rw-r-- 1 josh josh  116 Nov 11 14:01 config_sentence_transformers.json\n",
      "-rw-rw-r-- 1 josh josh  669 Nov 11 14:01 config.json\n",
      "-rw-rw-r-- 1 josh josh  438 Nov 11 14:01 tokenizer_config.json\n",
      "-rw-rw-r-- 1 josh josh  239 Nov 11 14:01 special_tokens_map.json\n",
      "-rw-rw-r-- 1 josh josh 418M Nov 11 14:01 pytorch_model.bin\n",
      "-rw-rw-r-- 1 josh josh 227K Nov 11 14:01 vocab.txt\n",
      "-rw-rw-r-- 1 josh josh 456K Nov 11 14:01 tokenizer.json\n",
      "-rw-rw-r-- 1 josh josh   53 Nov 11 14:01 sentence_bert_config.json\n",
      "drwxrwxr-x 2 josh josh 4.0K Nov 11 14:01 1_Pooling\n",
      "-rw-rw-r-- 1 josh josh 8.2K Nov 11 14:01 README.md\n",
      "-rw-rw-r-- 1 josh josh  229 Nov 11 14:01 modules.json\n"
     ]
    }
   ],
   "source": [
    "!ls -rtlh ./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_Pooling/\n",
      "1_Pooling/config.json\n",
      "config.json\n",
      "config_sentence_transformers.json\n",
      "modules.json\n",
      "pytorch_model.bin\n",
      "README.md\n",
      "sentence_bert_config.json\n",
      "special_tokens_map.json\n",
      "tokenizer_config.json\n",
      "tokenizer.json\n",
      "vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!cd model && tar czvf ../model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-484906661071/sagemaker/sentence-transformers/multi-qa-mpnet-base-dot-v1/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "fObj = open(\"model.tar.gz\", \"rb\")\n",
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)\n",
    "print(os.path.join(bucket, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-484906661071/sagemaker/sentence-transformers/multi-qa-mpnet-base-dot-v1/model.tar.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "pretrained_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "class StringPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = PyTorchModel(model_data = pretrained_model_data, \n",
    "                             role=role, \n",
    "                             entry_point ='inference.py',\n",
    "                             source_dir = './code', \n",
    "                             framework_version = '1.3.1',\n",
    "                             py_version = 'py3',\n",
    "                             predictor_cls=StringPredictor)\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.m5.large', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"Requested unsupported ContentType in content_type: application/octet-stream\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-inference-2021-11-12-01-18-29-802 in account 484906661071 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_99231/1268047767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'denim dress'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0membading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sm-multi-qa/lib/python3.8/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sm-multi-qa/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sm-multi-qa/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from primary with message \"Requested unsupported ContentType in content_type: application/octet-stream\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-inference-2021-11-12-01-18-29-802 in account 484906661071 for more information."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 881.9MB 1.8kB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (0.4.2)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (0.21.2)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (1.3.0)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Collecting nltk\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/b8/09ac15436591cefc0adc882798d5cf629f13addae0495b20b682219e3afe/nltk-3.6.5-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 1.6MB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hCollecting sentencepiece\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/49/2155d4078e9918003e77b6032a83d71995656bd05707d96e06a44cd6edf6/sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 770kB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hCollecting huggingface-hub\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/d9/467efa10b96c6ebb264496e9c4f72a1761f9a8a226de911d02696897845d/huggingface_hub-0.1.2-py3-none-any.whl (59kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 923kB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hCollecting packaging>=20.0\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/09/464d5df9f9ec1ab5054af6d097df6793e542f4aa426ba3062ec64409cab7/packaging-21.2-py3-none-any.whl (40kB)\n",
      "\u001b[K     |████████████████████████████████| 40kB 921kB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hCollecting regex!=2019.12.17\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/99/dad689cc27a041a01376957c4c3b0147bcc537c93dc01e03e89ebc5df807/regex-2021.11.10-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748kB)\n",
      "\u001b[K     |████████████████████████████████| 757kB 1.2MB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hCollecting filelock\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Downloading https://files.pythonhosted.org/packages/31/24/ee722b92f23b9ebd87783e893a75352c048bbbc1f67dce0d63b58b46cb48/filelock-3.3.2-py3-none-any.whl\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (2.22.0)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Collecting sacremoses\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/bf/15f8df78bce5eee8223553123173f010d426565980e457c559a71ecbecc3/sacremoses-0.0.46-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 1.3MB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Downloading https://files.pythonhosted.org/packages/c4/1f/e2238896149df09953efcc53bdcc7d23597d6c53e428c30e572eda5ec6eb/importlib_metadata-4.8.2-py3-none-any.whl\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (5.1.2)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Collecting dataclasses; python_version < \"3.7\"\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Downloading https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Collecting typing-extensions\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Downloading https://files.pythonhosted.org/packages/74/60/18783336cc7fcdd95dae91d73477830aa53f5d3181ae4fe20491d7fc3199/typing_extensions-3.10.0.2-py3-none-any.whl\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (1.12.0)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (6.2.0)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (0.14.1)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (7.0)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Collecting pyparsing<3,>=2.0.2\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 990kB/s \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (2019.11.28)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (1.25.7)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.4)\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Collecting zipp>=0.5\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Downloading https://files.pythonhosted.org/packages/bd/df/d4a4974a3e3957fd1c1fa3082366d7fff6e428ddb55f074bf64876f8e8ad/zipp-3.6.0-py3-none-any.whl\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Building wheels for collected packages: sentence-transformers\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-cp36-none-any.whl size=121000 sha256=4bebaa62aec4aa7a9d07e655443bac26cd1ef05dffcefa8b604f0e51ce67d19b\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/a5/73/00/99c924db76ef4ea1ddd1a429ff6aab1bad2ac629d064077e0b\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Successfully built sentence-transformers\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[31mERROR: sagemaker-pytorch-serving-container 1.3 has requirement numpy==1.16.4, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m \u001b[31mERROR: sagemaker-pytorch-serving-container 1.3 has requirement torch==1.3.1, but you'll have torch 1.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Installing collected packages: filelock, typing-extensions, zipp, importlib-metadata, pyparsing, packaging, huggingface-hub, regex, tokenizers, sacremoses, dataclasses, numpy, transformers, torch, nltk, sentencepiece, sentence-transformers\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Found existing installation: numpy 1.16.4\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m     Uninstalling numpy-1.16.4:\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m       Successfully uninstalled numpy-1.16.4\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m   Found existing installation: torch 1.3.1\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m     Uninstalling torch-1.3.1:\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m       Successfully uninstalled torch-1.3.1\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Successfully installed dataclasses-0.8 filelock-3.3.2 huggingface-hub-0.1.2 importlib-metadata-4.8.2 nltk-3.6.5 numpy-1.19.5 packaging-21.2 pyparsing-2.4.7 regex-2021.11.10 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.0 transformers-4.12.3 typing-extensions-3.10.0.2 zipp-3.6.0\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:31,452 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m MMS Home: /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Current directory: /\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Temp directory: /home/model-server/tmp\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Number of GPUs: 0\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Number of CPUs: 12\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Max heap size: 6651 M\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Python executable: /opt/conda/bin/python\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Management address: http://0.0.0.0:8080\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Initial Models: ALL\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Log dir: /logs\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Netty threads: 0\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Netty client threads: 0\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Default workers per model: 12\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:31,873 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,014 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,464 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,466 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]72\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,467 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,469 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,495 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,496 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9011\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,496 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]77\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,497 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,497 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,497 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,497 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]75\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,499 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,501 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,501 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]73\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,506 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,509 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,519 [INFO ] W-9011-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9011\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,520 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,522 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]74\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,523 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,524 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,527 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,525 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,533 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,537 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,605 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9009\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,609 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9008\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,611 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]78\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,612 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,613 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]80\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,613 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,614 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,614 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,614 [INFO ] W-9009-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9009\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,617 [INFO ] W-9008-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9008\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,661 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,662 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]71\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,664 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,664 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,665 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,679 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9010\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,680 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]81\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,680 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,681 [INFO ] W-9010-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9010\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,681 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,695 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,695 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]82\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,696 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,696 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,697 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,697 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,702 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,702 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]70\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,703 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,704 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,704 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,705 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]76\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,706 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,707 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,707 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,839 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,843 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,843 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9002.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,845 [INFO ] W-9011-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9011.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,843 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9003.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,843 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9005.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,848 [INFO ] W-9010-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9010.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,850 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9007.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m Model server started.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,854 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9004.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,857 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9001.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,862 [INFO ] W-9008-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9008.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,864 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9006.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:32,870 [INFO ] W-9009-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9009.\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:36,813 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3824\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:36,814 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3809\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:36,933 [INFO ] W-9009-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3946\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:36,979 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3993\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:36,994 [INFO ] W-9008-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4008\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:37,015 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4025\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:37,319 [INFO ] W-9011-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4332\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:37,341 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4343\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:37,376 [INFO ] W-9010-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4381\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:37,395 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4409\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:37,478 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4489\n",
      "\u001b[36moka7e72le0-algo-1-w90ig |\u001b[0m 2021-11-12 01:48:37,488 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4494\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "payload = str('Test String')\n",
    "features = predictor.predict(payload)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ea3f716968a89b8a90a229b19298b81f8074fd44dc01f157f1e0081a3042a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('sm-multi-qa': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
